{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.3-fashion-mnist-with-a-convolution-network-in-google-colab-with-gpus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MVxHs_gEYWF",
        "outputId": "7c4d9538-35cb-469e-c1b5-a2603ee456ad"
      },
      "source": [
        "\"\"\"\n",
        "Lab 3.3 - Fashion MNIST with a Convolution Network\n",
        "\n",
        "Author:\n",
        "- Rodrigo Jorge Ribeiro (rj.ribeiro@campus.fct.unl.pt)\n",
        "- Ruben Andre Barreiro (r.barreiro@campus.fct.unl.pt)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Import the Libraries and Packages\n",
        "\n",
        "# Import the Operative System Library as operative_system\n",
        "import os as operative_system\n",
        "\n",
        "# Disable all the Debugging Logs from TensorFlow Library\n",
        "operative_system.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# Import the Multiprocessing Library\n",
        "import multiprocessing\n",
        "\n",
        "# Import the TensorFlow Library\n",
        "import tensorflow\n",
        "\n",
        "# Import Keras from the TensorFlow Library\n",
        "from tensorflow import keras\n",
        "\n",
        "# Import the Stochastic Gradient Descent (SGD) Optimizer\n",
        "# from the TensorFlow.Keras.Optimizers Module\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Import the Backend Module from the TensorFlow.Python.Keras Python's Module\n",
        "from tensorflow.python.keras import backend as keras_backend\n",
        "\n",
        "# Import the Sequential from the TensorFlow.Keras.Models Module\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Import the BatchNormalization, Conv2D, MaxPooling2D from the TensorFlow.Keras.Layers Module\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D\n",
        "\n",
        "# Import the Activation, Flatten, Dropout and Dense from the TensorFlow.Keras.Layers Module\n",
        "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n",
        "\n",
        "\n",
        "# Constants\n",
        "\n",
        "# The boolean flag, to keep information about\n",
        "# the use of High-Performance Computing (with CPUs and GPUs)\n",
        "TENSORFLOW_KERAS_HPC_BACKEND_SESSION = True\n",
        "\n",
        "# The Number of CPU's Processors/Cores\n",
        "NUM_CPU_PROCESSORS_CORES = multiprocessing.cpu_count()\n",
        "\n",
        "# The Number of GPU's Devices\n",
        "NUM_GPU_DEVICES = len(tensorflow.config.list_physical_devices('GPU'))\n",
        "\n",
        "# The Learning Rate for the Stochastic Gradient Descent (SGD) Optimizer of\n",
        "# the Convolution Neural Network (CNN), as 1%\n",
        "INITIAL_LEARNING_RATE = 0.01\n",
        "\n",
        "# The Number of Epochs for the Stochastic Gradient Descent (SGD) Optimizer of\n",
        "# the Convolution Neural Network (CNN), as 25\n",
        "NUM_EPOCHS = 25\n",
        "\n",
        "# The Size of the Batch for the the Convolution Neural Network (CNN), as 128\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "# If the boolean flag, to keep information about\n",
        "# the use of High-Performance Computing (with CPUs and GPUs) is set to True\n",
        "if TENSORFLOW_KERAS_HPC_BACKEND_SESSION:\n",
        "\n",
        "    # Print the information about if the Model will be executed,\n",
        "    # using High-Performance Computing (with CPUs and GPUs)\n",
        "    print('\\n')\n",
        "    print('It will be used High-Performance Computing (with CPUs and GPUs):')\n",
        "    print(' - Num. CPUS: ', NUM_CPU_PROCESSORS_CORES)\n",
        "    print(' - Num. GPUS: ', NUM_GPU_DEVICES)\n",
        "    print('\\n')\n",
        "\n",
        "    # Set the Configuration's Proto, for the given number of Devices (CPUs and GPUs)\n",
        "    configuration_proto = \\\n",
        "        tensorflow.compat.v1.ConfigProto(device_count={'CPU': NUM_CPU_PROCESSORS_CORES,\n",
        "                                                       'GPU': NUM_GPU_DEVICES})\n",
        "\n",
        "    # Configure a TensorFlow Session for High-Performance Computing (with CPUs and GPUs)\n",
        "    session = tensorflow.compat.v1.Session(config=configuration_proto)\n",
        "\n",
        "    # Set the current Keras' Backend, with previously configured\n",
        "    # TensorFlow Session for High-Performance Computing (with CPUs and GPUs)\n",
        "    keras_backend.set_session(session)\n",
        "\n",
        "\n",
        "# Load the Dataset of the Fashion Modified NIST (Fashion MNIST),\n",
        "# retrieving the Training and Testing Datasets\n",
        "((xs_features_training_data, ys_labels_training_data), (xs_features_testing_data, ys_labels_testing_data)) = \\\n",
        "    keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Reshape the xs (Features) of the Training Data to 28 x 28 x 1,\n",
        "# in order to fit the Convolution Neural Network (CNN)\n",
        "xs_features_training_data = xs_features_training_data.reshape((xs_features_training_data.shape[0], 28, 28, 1))\n",
        "\n",
        "# Reshape the xs (Features) of the Testing Data to 28 x 28 x 1,\n",
        "# in order to fit the Convolution Neural Network (CNN)\n",
        "xs_features_testing_data = xs_features_testing_data.reshape((xs_features_testing_data.shape[0], 28, 28, 1))\n",
        "\n",
        "# Normalize the xs (Features) of the Training Dataset\n",
        "xs_features_training_data_normalized = (xs_features_training_data.astype(\"float32\") / 255.0)\n",
        "\n",
        "# Normalize the xs (Features) of the Testing Dataset\n",
        "xs_features_testing_data_normalized = (xs_features_testing_data.astype(\"float32\") / 255.0)\n",
        "\n",
        "# Set one-hot encode for the ys (Labels) of the Training Set\n",
        "ys_labels_training_data = keras.utils.to_categorical(ys_labels_training_data, 10)\n",
        "\n",
        "# Set one-hot encode for the ys (Labels) of the Testing Set\n",
        "ys_labels_testing_data = keras.utils.to_categorical(ys_labels_testing_data, 10)\n",
        "\n",
        "\n",
        "# Create the Convolution Neural Network (CNN) Model\n",
        "def create_convolution_neural_network_model():\n",
        "\n",
        "    # Create the Sequential Model for the Convolution Neural Network (CNN)\n",
        "    convolution_neural_network_model = Sequential()\n",
        "\n",
        "    # 1st CONV => RELU => CONV => RELU => POOL layer set\n",
        "\n",
        "    # Add a first Convolution 2D Matrix, for the Input Data of\n",
        "    # the Fashion Modified NIST (Fashion MNIST),\n",
        "    # with 32 Filters and a Kernel 3x3, Same Padding and\n",
        "    # an Input Shape having a Batch Size of 28, with 28 Steps, as also,\n",
        "    # 1 Input Dimension (for one Color Channel - Grayscale Color)\n",
        "    convolution_neural_network_model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(28, 28, 1)))\n",
        "\n",
        "    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n",
        "    # for the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n",
        "    convolution_neural_network_model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Add the Batch Normalization Layer, to normalize the previous Layer,\n",
        "    # by re-centering and re-scaling the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST) and\n",
        "    # making the Convolution Neural Network (CNN) faster and more stable\n",
        "    convolution_neural_network_model.add(BatchNormalization(axis=-1))\n",
        "\n",
        "    # Add a second Convolution 2D Matrix, for the previous Data of\n",
        "    # the Fashion Modified NIST (Fashion MNIST),\n",
        "    # with 32 Filters and a Kernel 3x3, Same Padding and\n",
        "    # an Input Shape having a Batch Size of 28, with 28 Steps, as also,\n",
        "    # 1 Input Dimension (for one Color Channel - Grayscale Color)\n",
        "    convolution_neural_network_model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "\n",
        "    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n",
        "    # for the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n",
        "    convolution_neural_network_model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Add the Batch Normalization Layer, to normalize the previous Layer,\n",
        "    # by re-centering and re-scaling the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST) and\n",
        "    # making the Convolution Neural Network (CNN) faster and more stable\n",
        "    convolution_neural_network_model.add(BatchNormalization(axis=-1))\n",
        "\n",
        "    # Add a Max Pooling 2D Sample-Based Discretization Process Layer,\n",
        "    # for the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST) and a 2x2 Pool\n",
        "    convolution_neural_network_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Add the Dropout Layer, for Regularization of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST),\n",
        "    # by using as hyper-parameter, the rate of 25%\n",
        "    # NOTE:\n",
        "    # - Dropout Layer in Convolution Neural Networks is generally, not very useful;\n",
        "    # - Comment/Uncomment, if you want to try it or not;\n",
        "    convolution_neural_network_model.add(Dropout(0.25))\n",
        "\n",
        "    # 2nd CONV => RELU => CONV => RELU => POOL layer set\n",
        "\n",
        "    # Add a first Convolution 2D Matrix, for the Input Data of\n",
        "    # the Fashion Modified NIST (Fashion MNIST),\n",
        "    # with 64 Filters and a Kernel 3x3, Same Padding and\n",
        "    # an Input Shape having a Batch Size of 28, with 28 Steps, as also,\n",
        "    # 1 Input Dimension (for one Color Channel - Grayscale Color)\n",
        "    convolution_neural_network_model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\n",
        "    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n",
        "    # for the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n",
        "    convolution_neural_network_model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Add the Batch Normalization Layer, to normalize the previous Layer,\n",
        "    # by re-centering and re-scaling the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST) and\n",
        "    # making the Convolution Neural Network (CNN) faster and more stable\n",
        "    convolution_neural_network_model.add(BatchNormalization(axis=-1))\n",
        "\n",
        "    # Add a second Convolution 2D Matrix, for the previous Data of\n",
        "    # the Fashion Modified NIST (Fashion MNIST),\n",
        "    # with 64 Filters and a Kernel 3x3, Same Padding and\n",
        "    # an Input Shape having a Batch Size of 28, with 28 Steps, as also,\n",
        "    # 1 Input Dimension (for one Color Channel - Grayscale Color)\n",
        "    convolution_neural_network_model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\n",
        "    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n",
        "    # for the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n",
        "    convolution_neural_network_model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Add the Batch Normalization Layer, to normalize the previous Layer,\n",
        "    # by re-centering and re-scaling the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST) and\n",
        "    # making the Convolution Neural Network (CNN) faster and more stable\n",
        "    convolution_neural_network_model.add(BatchNormalization(axis=-1))\n",
        "\n",
        "    # Add a Max Pooling 2D Sample-Based Discretization Process Layer,\n",
        "    # for the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST) and a 2x2 Pool\n",
        "    convolution_neural_network_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Add the Dropout Layer, for Regularization of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST),\n",
        "    # by using as hyper-parameter, the rate of 25%\n",
        "    # NOTE:\n",
        "    # - Dropout Layer in Convolution Neural Networks is generally, not very useful;\n",
        "    # - Comment/Uncomment, if you want to try it or not;\n",
        "    convolution_neural_network_model.add(Dropout(0.25))\n",
        "\n",
        "    # 1st (and only) set of FC => RELU layers\n",
        "\n",
        "    # Flatten the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n",
        "    # NOTE:\n",
        "    # - This is needed to flatten the input into a single dimension for the features,\n",
        "    #   which is what the next Dense Layer needs;\n",
        "    convolution_neural_network_model.add(Flatten())\n",
        "\n",
        "    # Add a Dense Matrix of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST) and 512 Units\n",
        "    convolution_neural_network_model.add(Dense(512))\n",
        "\n",
        "    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n",
        "    # for the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n",
        "    convolution_neural_network_model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Add the Batch Normalization Layer, to normalize the previous Layer,\n",
        "    # by re-centering and re-scaling the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST) and\n",
        "    # making the Convolution Neural Network (CNN) faster and more stable\n",
        "    convolution_neural_network_model.add(BatchNormalization())\n",
        "\n",
        "    # Add the Dropout Layer, for Regularization of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST),\n",
        "    # by using as hyper-parameter, the rate of 50%\n",
        "    # NOTE:\n",
        "    # - Dropout Layer in Convolution Neural Networks is generally, not very useful;\n",
        "    # - Comment/Uncomment, if you want to try it or not;\n",
        "    convolution_neural_network_model.add(Dropout(0.5))\n",
        "\n",
        "    # SoftMax Classifier\n",
        "\n",
        "    # Add a Dense Matrix of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST) and 10 Units\n",
        "    convolution_neural_network_model.add(Dense(10))\n",
        "\n",
        "    # Add the Softmax as Activation Function Layer,\n",
        "    # for the Data of the Convolution Neural Network (CNN),\n",
        "    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n",
        "    convolution_neural_network_model.add(Activation(\"softmax\"))\n",
        "\n",
        "    # Return the Convolution Neural Network (CNN)\n",
        "    return convolution_neural_network_model\n",
        "\n",
        "\n",
        "# Initialise the Stochastic Gradient Descent (SGD) Optimizer,\n",
        "# with the Learning Rate of INIT_LR, Momentum of 90% and Decay of (INIT_LR / NUM_EPOCHS)\n",
        "stochastic_gradient_descent_optimizer = SGD(learning_rate=INITIAL_LEARNING_RATE,\n",
        "                                            momentum=0.9,\n",
        "                                            decay=(INITIAL_LEARNING_RATE / NUM_EPOCHS))\n",
        "\n",
        "# Create the Convolution Neural Network (CNN) Model for the Data of\n",
        "# the Fashion Modified NIST (Fashion MNIST)\n",
        "cnn_model = create_convolution_neural_network_model()\n",
        "\n",
        "# Compile the Convolution Neural Network (CNN) Model,\n",
        "# with the given Categorical Cross Entropy Loss/Error Function and\n",
        "# the Stochastic Gradient Descent (SGD) Optimizer\n",
        "cnn_model.compile(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=stochastic_gradient_descent_optimizer,\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "# Print the Log for the Fitting of the Convolution Neural Network (CNN) Model\n",
        "print(f\"\\nFitting the Convolution Neural Network (CNN) Model for {NUM_EPOCHS} Epochs \"\n",
        "      f\"with a Batch Size of {BATCH_SIZE} and an Initial Learning Rate of {INITIAL_LEARNING_RATE}...\\n\")\n",
        "\n",
        "# Train the Convolution Neural Network (CNN) Model for NUM_EPOCHS,\n",
        "# with the Training Data for the Training Set and the Testing Data for the Validation Set\n",
        "cnn_model_training_history = cnn_model.fit(xs_features_training_data, ys_labels_training_data,\n",
        "                                           validation_data=(xs_features_testing_data, ys_labels_testing_data),\n",
        "                                           batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,)\n",
        "\n",
        "\n",
        "# the use of High-Performance Computing (with CPUs and GPUs) is set to True\n",
        "if TENSORFLOW_KERAS_HPC_BACKEND_SESSION:\n",
        "\n",
        "    # Clear the current session of the Keras' Backend\n",
        "    keras_backend.clear_session()\n",
        "\n",
        "\n",
        "# Print the final Log for the Fitting of the Convolution Neural Network (CNN) Model\n",
        "print(\"\\nThe Fitting of the Convolution Neural Network (CNN) Model is complete!!!\\n\")\n",
        "\n",
        "# Save the Weights of the Neurons of the Convolution Neural Network (CNN) Model\n",
        "cnn_model.save_weights(\"fashion_mnist_model.h5\")\n",
        "\n",
        "# Convert the Convolution Neural Network (CNN) Model to a JSON Object\n",
        "cnn_model_json_object = cnn_model.to_json()\n",
        "\n",
        "# Write the Convolution Neural Network (CNN) Model as a JSON Object\n",
        "with open(\"fashion_mnist_model.json\", \"w\") as json_file:\n",
        "    json_file.write(cnn_model_json_object)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "It will be used High-Performance Computing (with CPUs and GPUs):\n",
            " - Num. CPUS:  2\n",
            " - Num. GPUS:  1\n",
            "\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "\n",
            "Fitting the Convolution Neural Network (CNN) Model for 25 Epochs with a Batch Size of 128 and an Initial Learning Rate of 0.01...\n",
            "\n",
            "Epoch 1/25\n",
            "469/469 [==============================] - 42s 25ms/step - loss: 0.7382 - accuracy: 0.7598 - val_loss: 0.3213 - val_accuracy: 0.8826\n",
            "Epoch 2/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.3283 - accuracy: 0.8812 - val_loss: 0.3097 - val_accuracy: 0.8851\n",
            "Epoch 3/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.2937 - accuracy: 0.8945 - val_loss: 0.2585 - val_accuracy: 0.9061\n",
            "Epoch 4/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.2563 - accuracy: 0.9062 - val_loss: 0.2774 - val_accuracy: 0.8947\n",
            "Epoch 5/25\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.2442 - accuracy: 0.9115 - val_loss: 0.2280 - val_accuracy: 0.9172\n",
            "Epoch 6/25\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.2312 - accuracy: 0.9164 - val_loss: 0.2213 - val_accuracy: 0.9214\n",
            "Epoch 7/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.2247 - accuracy: 0.9187 - val_loss: 0.2156 - val_accuracy: 0.9211\n",
            "Epoch 8/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.2109 - accuracy: 0.9218 - val_loss: 0.2118 - val_accuracy: 0.9217\n",
            "Epoch 9/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.2039 - accuracy: 0.9248 - val_loss: 0.2124 - val_accuracy: 0.9212\n",
            "Epoch 10/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.2005 - accuracy: 0.9250 - val_loss: 0.2111 - val_accuracy: 0.9227\n",
            "Epoch 11/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1888 - accuracy: 0.9302 - val_loss: 0.2028 - val_accuracy: 0.9249\n",
            "Epoch 12/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1918 - accuracy: 0.9303 - val_loss: 0.2003 - val_accuracy: 0.9271\n",
            "Epoch 13/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1824 - accuracy: 0.9325 - val_loss: 0.2143 - val_accuracy: 0.9204\n",
            "Epoch 14/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1811 - accuracy: 0.9327 - val_loss: 0.1979 - val_accuracy: 0.9275\n",
            "Epoch 15/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1780 - accuracy: 0.9340 - val_loss: 0.1946 - val_accuracy: 0.9290\n",
            "Epoch 16/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1745 - accuracy: 0.9350 - val_loss: 0.1953 - val_accuracy: 0.9303\n",
            "Epoch 17/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1718 - accuracy: 0.9358 - val_loss: 0.1931 - val_accuracy: 0.9298\n",
            "Epoch 18/25\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.1678 - accuracy: 0.9377 - val_loss: 0.1948 - val_accuracy: 0.9311\n",
            "Epoch 19/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1666 - accuracy: 0.9385 - val_loss: 0.1919 - val_accuracy: 0.9313\n",
            "Epoch 20/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1619 - accuracy: 0.9411 - val_loss: 0.1913 - val_accuracy: 0.9304\n",
            "Epoch 21/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1585 - accuracy: 0.9421 - val_loss: 0.1926 - val_accuracy: 0.9297\n",
            "Epoch 22/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1562 - accuracy: 0.9423 - val_loss: 0.1952 - val_accuracy: 0.9294\n",
            "Epoch 23/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1544 - accuracy: 0.9422 - val_loss: 0.1913 - val_accuracy: 0.9317\n",
            "Epoch 24/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1537 - accuracy: 0.9432 - val_loss: 0.1887 - val_accuracy: 0.9315\n",
            "Epoch 25/25\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.1510 - accuracy: 0.9445 - val_loss: 0.1937 - val_accuracy: 0.9315\n",
            "\n",
            "The Fitting of the Convolution Neural Network (CNN) Model is complete!!!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}