{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.3-fashion-mnist-with-a-convolution-network-in-google-colab-with-gpus.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyME7cwN9di8ilZz8AxYoovQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-MVxHs_gEYWF","executionInfo":{"status":"ok","timestamp":1617884227462,"user_tz":-60,"elapsed":167785,"user":{"displayName":"Rúben André Barreiro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gixyf3b5GZJdMA4h3yT8CuZ8eWW9NNWUHBxj6lN9A=s64","userId":"04040584489886292429"}},"outputId":"b2c4f20d-c035-4f9d-d748-a9ad03c062ce"},"source":["\"\"\"\n","Lab 3.3 - Fashion MNIST with a Convolution Network\n","\n","Author:\n","- Rodrigo Jorge Ribeiro (rj.ribeiro@campus.fct.unl.pt)\n","- Ruben Andre Barreiro (r.barreiro@campus.fct.unl.pt)\n","\n","NOTE:\n","- Import to the Google Colaboratory to run this Jupyter Notebook;\n","- Go to Edit -> Notebook settings to change\n","  the Hardware accelerator to GPU/TPU;\n","- Set the GPU device as default, with tensorflow.device('/device:GPU:0');\n","\n","\"\"\"\n","\n","# Import the Libraries and Packages\n","\n","# Import the Operative System Library as operative_system\n","import os as operative_system\n","\n","# Disable all the Debugging Logs from TensorFlow Library\n","operative_system.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","# Import TensorFlow witht the tensorflow alias\n","import tensorflow as tensorflow\n","\n","# Import Keras from the TensorFlow Library\n","from tensorflow import keras\n","\n","# Import the Stochastic Gradient Descent (SGD) Optimizer\n","# from the TensorFlow.Keras.Optimizers Module\n","from tensorflow.keras.optimizers import SGD\n","\n","# Import the Sequential from the TensorFlow.Keras.Models Module\n","from tensorflow.keras.models import Sequential\n","\n","# Import the BatchNormalization, Conv2D, MaxPooling2D from the TensorFlow.Keras.Layers Module\n","from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D\n","\n","# Import the Activation, Flatten, Dropout and Dense from the TensorFlow.Keras.Layers Module\n","from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n","\n","\n","# Constants\n","\n","# The Learning Rate for the Stochastic Gradient Descent (SGD) Optimizer of\n","# the Convolution Neural Network (CNN), as 1%\n","INITIAL_LEARNING_RATE = 0.01\n","\n","# The Number of Epochs for the Stochastic Gradient Descent (SGD) Optimizer of\n","# the Convolution Neural Network (CNN), as 25\n","NUM_EPOCHS = 25\n","\n","# The Size of the Batch for the the Convolution Neural Network (CNN), as 128\n","BATCH_SIZE = 128\n","\n","\n","# Load the Dataset of the Fashion Modified NIST (Fashion MNIST),\n","# retrieving the Training and Testing Datasets\n","((xs_features_training_data, ys_labels_training_data), (xs_features_testing_data, ys_labels_testing_data)) = \\\n","    keras.datasets.fashion_mnist.load_data()\n","\n","# Reshape the xs (Features) of the Training Data to 28 x 28 x 1,\n","# in order to fit the Convolution Neural Network (CNN)\n","xs_features_training_data = xs_features_training_data.reshape((xs_features_training_data.shape[0], 28, 28, 1))\n","\n","# Reshape the xs (Features) of the Testing Data to 28 x 28 x 1,\n","# in order to fit the Convolution Neural Network (CNN)\n","xs_features_testing_data = xs_features_testing_data.reshape((xs_features_testing_data.shape[0], 28, 28, 1))\n","\n","# Normalize the xs (Features) of the Training Dataset\n","xs_features_training_data_normalized = (xs_features_training_data.astype(\"float32\") / 255.0)\n","\n","# Normalize the xs (Features) of the Testing Dataset\n","xs_features_testing_data_normalized = (xs_features_testing_data.astype(\"float32\") / 255.0)\n","\n","# Set one-hot encode for the ys (Labels) of the Training Set\n","ys_labels_training_data = keras.utils.to_categorical(ys_labels_training_data, 10)\n","\n","# Set one-hot encode for the ys (Labels) of the Testing Set\n","ys_labels_testing_data = keras.utils.to_categorical(ys_labels_testing_data, 10)\n","\n","\n","# Create the Convolution Neural Network (CNN) Model\n","def create_convolution_neural_network_model():\n","\n","    # Create the Sequential Model for the Convolution Neural Network (CNN)\n","    convolution_neural_network_model = Sequential()\n","\n","    # Add a first Convolution 2D Matrix, for the Input Data of\n","    # the Fashion Modified NIST (Fashion MNIST),\n","    # with 32 Filters and a Kernel 3x3, Same Padding and\n","    # an Input Shape having a Batch Size of 28, with 28 Steps, as also,\n","    # 1 Input Dimension (for one Color Channel - Grayscale Color)\n","    convolution_neural_network_model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(28, 28, 1)))\n","\n","    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n","    # for the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n","    convolution_neural_network_model.add(Activation(\"relu\"))\n","\n","    # Add a second Convolution 2D Matrix, for the previous Data of\n","    # the Fashion Modified NIST (Fashion MNIST),\n","    # with 32 Filters and a Kernel 3x3, Same Padding and\n","    # an Input Shape having a Batch Size of 28, with 28 Steps, as also,\n","    # 1 Input Dimension (for one Color Channel - Grayscale Color)\n","    convolution_neural_network_model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(28, 28, 1)))\n","\n","    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n","    # for the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n","    convolution_neural_network_model.add(Activation(\"relu\"))\n","\n","    # Add the Batch Normalization Layer, to normalize the previous Layer,\n","    # by re-centering and re-scaling the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST) and\n","    # making the Convolution Neural Network (CNN) faster and more stable\n","    convolution_neural_network_model.add(BatchNormalization())\n","\n","    # Add a Max Pooling 2D Sample-Based Discretization Process Layer,\n","    # for the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST) and a 2x2 Pool\n","    convolution_neural_network_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","    # Add the Dropout Layer, for Regularization of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST),\n","    # by using as hyper-parameter, the rate of 25%\n","    # NOTE:\n","    # - Dropout Layer in Convolution Neural Networks is generally, not very useful;\n","    # - Comment/Uncomment, if you want to try it or not;\n","    convolution_neural_network_model.add(Dropout(0.25))\n","\n","    # Add a first Convolution 2D Matrix, for the Input Data of\n","    # the Fashion Modified NIST (Fashion MNIST),\n","    # with 64 Filters and a Kernel 3x3, Same Padding and\n","    # an Input Shape having a Batch Size of 28, with 28 Steps, as also,\n","    # 1 Input Dimension (for one Color Channel - Grayscale Color)\n","    convolution_neural_network_model.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=(28, 28, 1)))\n","\n","    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n","    # for the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n","    convolution_neural_network_model.add(Activation(\"relu\"))\n","\n","    # Add a second Convolution 2D Matrix, for the previous Data of\n","    # the Fashion Modified NIST (Fashion MNIST),\n","    # with 64 Filters and a Kernel 3x3, Same Padding and\n","    # an Input Shape having a Batch Size of 28, with 28 Steps, as also,\n","    # 1 Input Dimension (for one Color Channel - Grayscale Color)\n","    convolution_neural_network_model.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=(28, 28, 1)))\n","\n","    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n","    # for the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n","    convolution_neural_network_model.add(Activation(\"relu\"))\n","\n","    # Add a Max Pooling 2D Sample-Based Discretization Process Layer,\n","    # for the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST) and a 2x2 Pool\n","    convolution_neural_network_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","    # Flatten the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n","    # NOTE:\n","    # - This is needed to flatten the input into a single dimension for the features,\n","    #   which is what the next Dense Layer needs;\n","    convolution_neural_network_model.add(Flatten())\n","\n","    # Add a Dense Matrix of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST) and 10 Units\n","    convolution_neural_network_model.add(Dense(512))\n","\n","    # Add the Rectified Linear Unit (ReLU) as Activation Function Layer,\n","    # for the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n","    convolution_neural_network_model.add(Activation(\"relu\"))\n","\n","    # Add the Batch Normalization Layer, to normalize the previous Layer,\n","    # by re-centering and re-scaling the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST) and\n","    # making the Convolution Neural Network (CNN) faster and more stable\n","    convolution_neural_network_model.add(BatchNormalization())\n","\n","    # Add the Dropout Layer, for Regularization of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST),\n","    # by using as hyper-parameter, the rate of 50%\n","    # NOTE:\n","    # - Dropout Layer in Convolution Neural Networks is generally, not very useful;\n","    # - Comment/Uncomment, if you want to try it or not;\n","    convolution_neural_network_model.add(Dropout(0.5))\n","\n","    # Flatten the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n","    # NOTE:\n","    # - This is needed to flatten the input into a single dimension for the features,\n","    #   which is what the next Dense Layer needs;\n","    convolution_neural_network_model.add(Flatten())\n","\n","    # Add a Dense Matrix of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST) and 10 Units\n","    convolution_neural_network_model.add(Dense(10))\n","\n","    # Add the Softmax as Activation Function Layer,\n","    # for the Data of the Convolution Neural Network (CNN),\n","    # with the Data of the Fashion Modified NIST (Fashion MNIST)\n","    convolution_neural_network_model.add(Activation(\"softmax\"))\n","\n","    # Return the Convolution Neural Network (CNN)\n","    return convolution_neural_network_model\n","\n","\n","# With the GPU Hardware, for the Execution\n","with tensorflow.device('/device:GPU:0'):\n","\n","  # Initialise the Stochastic Gradient Descent (SGD) Optimizer,\n","  # with the Learning Rate of INIT_LR, Momentum of 90% and Decay of (INIT_LR / NUM_EPOCHS)\n","  stochastic_gradient_descent_optimizer = SGD(learning_rate=INITIAL_LEARNING_RATE,\n","                                              momentum=0.9,\n","                                              decay=(INITIAL_LEARNING_RATE / NUM_EPOCHS))\n","\n","  # Create the Convolution Neural Network (CNN) Model for the Data of\n","  # the Fashion Modified NIST (Fashion MNIST)\n","  cnn_model = create_convolution_neural_network_model()\n","\n","  # Compile the Convolution Neural Network (CNN) Model,\n","  # with the given Categorical Cross Entropy Loss/Error Function and\n","  # the Stochastic Gradient Descent (SGD) Optimizer\n","  cnn_model.compile(loss=\"categorical_crossentropy\",\n","                    optimizer=stochastic_gradient_descent_optimizer,\n","                    metrics=[\"accuracy\"])\n","\n","  # Print the Log for the Fitting of the Convolution Neural Network (CNN) Model\n","  print(f\"\\nFitting the Convolution Neural Network (CNN) Model for {NUM_EPOCHS} Epochs \"\n","        f\"with a Batch Size of {BATCH_SIZE} and an Initial Learning Rate of {INITIAL_LEARNING_RATE}...\\n\")\n","\n","  # Train the Convolution Neural Network (CNN) Model for NUM_EPOCHS,\n","  # with the Training Data for the Training Set and the Testing Data for the Validation Set\n","  cnn_model_training_history = cnn_model.fit(xs_features_training_data, ys_labels_training_data,\n","                                            validation_data=(xs_features_testing_data, ys_labels_testing_data),\n","                                            batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)\n","\n","  # Print the final Log for the Fitting of the Convolution Neural Network (CNN) Model\n","  print(\"\\nThe Fitting of the Convolution Neural Network (CNN) Model is complete!!!\\n\")\n","\n","  # Save the Weights of the Neurons of the Convolution Neural Network (CNN) Model\n","  cnn_model.save_weights(\"fashion_mnist_model.h5\")\n","\n","  # Convert the Convolution Neural Network (CNN) Model to a JSON Object\n","  cnn_model_json_object = cnn_model.to_json()\n","\n","  # Write the Convolution Neural Network (CNN) Model as a JSON Object\n","  with open(\"fashion_mnist_model.json\", \"w\") as json_file:\n","      json_file.write(cnn_model_json_object)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","\n","Fitting the Convolution Neural Network (CNN) Model for 25 Epochs with a Batch Size of 128 and an Initial Learning Rate of 0.01...\n","\n","Epoch 1/25\n","469/469 [==============================] - 39s 12ms/step - loss: 0.6788 - accuracy: 0.7655 - val_loss: 0.3686 - val_accuracy: 0.8598\n","Epoch 2/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.3531 - accuracy: 0.8707 - val_loss: 0.3142 - val_accuracy: 0.8875\n","Epoch 3/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.3078 - accuracy: 0.8882 - val_loss: 0.2904 - val_accuracy: 0.8920\n","Epoch 4/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2734 - accuracy: 0.9016 - val_loss: 0.2912 - val_accuracy: 0.8930\n","Epoch 5/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2476 - accuracy: 0.9093 - val_loss: 0.2481 - val_accuracy: 0.9079\n","Epoch 6/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2326 - accuracy: 0.9149 - val_loss: 0.2350 - val_accuracy: 0.9147\n","Epoch 7/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2210 - accuracy: 0.9180 - val_loss: 0.2278 - val_accuracy: 0.9167\n","Epoch 8/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2120 - accuracy: 0.9217 - val_loss: 0.2479 - val_accuracy: 0.9108\n","Epoch 9/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2055 - accuracy: 0.9254 - val_loss: 0.2189 - val_accuracy: 0.9199\n","Epoch 10/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1971 - accuracy: 0.9287 - val_loss: 0.2162 - val_accuracy: 0.9219\n","Epoch 11/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1877 - accuracy: 0.9299 - val_loss: 0.2134 - val_accuracy: 0.9243\n","Epoch 12/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1849 - accuracy: 0.9325 - val_loss: 0.2110 - val_accuracy: 0.9263\n","Epoch 13/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1761 - accuracy: 0.9371 - val_loss: 0.2256 - val_accuracy: 0.9204\n","Epoch 14/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1729 - accuracy: 0.9359 - val_loss: 0.2046 - val_accuracy: 0.9267\n","Epoch 15/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1637 - accuracy: 0.9398 - val_loss: 0.2052 - val_accuracy: 0.9252\n","Epoch 16/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1674 - accuracy: 0.9391 - val_loss: 0.2078 - val_accuracy: 0.9252\n","Epoch 17/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1586 - accuracy: 0.9412 - val_loss: 0.2018 - val_accuracy: 0.9263\n","Epoch 18/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1559 - accuracy: 0.9427 - val_loss: 0.1979 - val_accuracy: 0.9296\n","Epoch 19/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1511 - accuracy: 0.9436 - val_loss: 0.2028 - val_accuracy: 0.9281\n","Epoch 20/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1455 - accuracy: 0.9467 - val_loss: 0.1952 - val_accuracy: 0.9318\n","Epoch 21/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1443 - accuracy: 0.9464 - val_loss: 0.2035 - val_accuracy: 0.9275\n","Epoch 22/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1441 - accuracy: 0.9474 - val_loss: 0.1968 - val_accuracy: 0.9317\n","Epoch 23/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1427 - accuracy: 0.9477 - val_loss: 0.1958 - val_accuracy: 0.9323\n","Epoch 24/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1415 - accuracy: 0.9486 - val_loss: 0.1946 - val_accuracy: 0.9314\n","Epoch 25/25\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1366 - accuracy: 0.9508 - val_loss: 0.2001 - val_accuracy: 0.9283\n","\n","The Fitting of the Convolution Neural Network (CNN) Model is complete!!!\n","\n"],"name":"stdout"}]}]}